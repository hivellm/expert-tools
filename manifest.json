{
  "name": "expert-tools",
  "version": "0.1.0",
  "schema_version": "2.0",
  "description": "Tool orchestration expert designed to interpret tasks, select appropriate MCP/tool endpoints, and emit structured tool-call plans.",
  "author": "hivellm",
  "homepage": "https://github.com/hivellm/expert-tools",

  "base_models": [
    {
      "name": "F:/Node/hivellm/expert/models/Qwen3-0.6B",
      "sha256": "",
      "quantization": "int4",
      "rope_scaling": {
        "type": "ntk-by-parts",
        "factor": 8.0,
        "max_position_embeddings": 32768,
        "original_max_position_embeddings": 8192,
        "fine_grained": true,
        "_comment": "Same scaling used across Qwen3-based experts to maintain context length parity."
      },
      "prompt_template": "chatml",
      "adapters": [
        {
          "type": "dora",
          "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj", "up_proj", "down_proj"],
          "r": 16,
          "alpha": 32,
          "scaling": "dora",
          "dropout": 0.1,
          "path": "weights/qwen3-06b/checkpoint-TBD",
          "size_bytes": 0,
          "sha256": "",
          "_comment": "Placeholder DoRA adapter configuration. Final checkpoint and hash will be populated after Qwen-Max hyperparameter sweep."
        }
      ]
    }
  ],

  "soft_prompts": [],

  "constraints": {
    "max_chain": 6,
    "load_order": 7,
    "incompatible_with": [],
    "requires": ["expert-json"]
  },

  "capabilities": [
    "task:tool_invocation",
    "task:mcp_planning",
    "task:tool_routing",
    "feature:multi_step_planning",
    "feature:error_recovery",
    "feature:structured_output",
    "feature:tool_argument_validation",
    "feature:mcp_resource_selection",
    "feature:api_schema_reasoning",
    "format:json"
  ],

  "limitations": [
    "limited_tool_catalog",
    "no_direct_execution",
    "requires_runtime_validation"
  ],

  "routing": {
    "keywords": [
      "tool",
      "tools",
      "mcp",
      "plugin",
      "call",
      "invoke",
      "planner",
      "plan",
      "api",
      "action",
      "run",
      "query docs",
      "context7",
      "vectorizer",
      "search tool",
      "http request"
    ],
    "router_hint": "task=tool_invocation OR task=mcp_planning",
    "priority": 0.8,
    "_comment": "Priority slightly lower than specialized experts to allow domain experts to claim tasks first."
  },

  "perf": {
    "latency_ms_overhead": 3.5,
    "vram_mb_overhead": 22,
    "supported_batch_sizes": [1, 2, 4],
    "_comment": "Placeholder until benchmarked with finalized adapter."
  },

  "runtime": {
    "candle_compatible": true,
    "requires_kv_cache_persistence": true,
    "attention_kernel": "flash-v2",
    "tool_validation_middleware": true,
    "max_tool_retries": 3,
    "tool_timeout_ms": 5000,
    "schema_validation": "strict",
    "_comment": "Matches Qwen3 runtime expectations. JSON/tool validation middleware enforces schema compliance and retries."
  },

  "training": {
    "dataset": {
      "path": "datasets/train.jsonl",
      "format": "jsonl",
      "streaming": false,
      "validation_path": "datasets/validation.jsonl",
      "validation_split": 0.15,
      "error_injection_ratio": 0.3,
      "_comment": "Curated tool/MCP dialogues (English-first). 15% reserved for validation; 30% of batches include synthetic failure cases."
    },
    "config": {
      "method": "sft",
      "adapter_type": "dora",
      "use_unsloth": true,
      "rank": 16,
      "alpha": 32,
      "learning_rate": 0.00045,
      "warmup_steps": 0,
      "warmup_ratio": 0.1,
      "lr_scheduler": "cosine_with_restarts",
      "lr_scheduler_kwargs": {
        "num_cycles": 3
      },
      "epochs": 2.5,
      "batch_size": 4,
      "gradient_accumulation_steps": 6,
      "target_modules": [
        "q_proj",
        "k_proj",
        "v_proj",
        "o_proj",
        "up_proj",
        "down_proj"
      ],
      "max_steps": 0,
      "logging_steps": 10,
      "eval_steps": 100,
      "save_steps": 100,
      "gradient_checkpointing": "full",
      "memory_clear_every": 50,
      "bf16": true,
      "use_tf32": true,
      "use_sdpa": false,
      "dataloader_num_workers": 2,
      "dataloader_pin_memory": true,
      "dataloader_persistent_workers": false,
      "_comment": "Updated hyperparameters for tool-planning SFT (effective batch 24, cosine restarts, Windows-friendly dataloader/VRAM settings)."
    },
    "decoding": {
      "temperature": 0.1,
      "top_p": 0.9,
      "top_k": 50,
      "stop_sequences": [
        "```",
        "}",
        "\n\n"
      ],
      "grammar_type": "tool-call",
      "validation": "schema-strict",
      "max_new_tokens": 512,
      "_comment": "Deterministic decoding tuned for tool-call JSON generation."
    }
  },

  "license": "Apache-2.0",

  "evaluation": {
    "suite": [
      "tests/test_cases.json"
    ],
    "test_set_size": 0,
    "metrics": {
      "tool_selection_accuracy": 0.0,
      "argument_validity": 0.0,
      "fallback_effectiveness": 0.0,
      "schema_compliance": 0.0,
      "tool_call_success_rate": 0.0
    },
    "failure_modes": [
      "hallucinated_tools",
      "missing_required_args",
      "invalid_json_structure",
      "infinite_tool_loops"
    ],
    "_comment": "Evaluation harness will leverage expert-cli compare workflow once dataset/tests are populated. Metrics aligned with production tool-calling KPIs."
  }
}
